{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 24 examples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataset():\n",
    "    \n",
    "    data = [\n",
    "        {\"text\": \"I'm Sajal, a sophomore at MUJ, passionate about LLMs and cutting-edge AI research.\"},\n",
    "        {\"text\": \"Exploring AI is my favorite thing! From transformers to fine-tuning models, I love working on LLMs.\"},\n",
    "        {\"text\": \"Whenever I get free time, I binge-watch Netflix. Sci-fi series like 3 Body Problem and Ragnarok fascinate me.\"},\n",
    "        {\"text\": \"Traveling excites me! I've explored the US, Singapore, Dubai, and many parts of India, and I can't wait to visit more places.\"},\n",
    "        {\"text\": \"There's something about coding AI models that keeps me hooked—it's like solving a puzzle that never ends.\"},\n",
    "        {\"text\": \"I love discussing how AI will shape the future, especially in areas like NLP and generative models.\"},\n",
    "        {\"text\": \"Optimizing large language models for efficiency is something I’ve been experimenting with a lot.\"},\n",
    "        {\"text\": \"My Netflix watchlist is packed with sci-fi, mystery, and adventure. Shows like Away and Ragnarok are absolute gems!\"},\n",
    "        {\"text\": \"Visiting new places opens my mind. Every country I travel to gives me a new perspective on life.\"},\n",
    "        {\"text\": \"At MUJ, I’m always looking for ways to apply AI in real-world applications and projects.\"},\n",
    "        {\"text\": \"Building AI models that can understand human language is both challenging and rewarding.\"},\n",
    "        {\"text\": \"Fine-tuning LLMs requires patience, but it's exciting to see them get better at responding.\"},\n",
    "        {\"text\": \"One of my goals is to contribute to open-source AI projects that push the limits of machine learning.\"},\n",
    "        {\"text\": \"I often get lost in deep AI research papers, trying to understand the latest advancements.\"},\n",
    "        {\"text\": \"Sci-fi isn't just entertainment for me; it's an inspiration. AI and the future of technology intrigue me.\"},\n",
    "        {\"text\": \"Dubai's skyline, Singapore's efficiency, and the energy of New York—every city has something unique!\"},\n",
    "        {\"text\": \"Experimenting with different AI architectures helps me grasp what makes LLMs so powerful.\"},\n",
    "        {\"text\": \"AI deployment fascinates me—making models efficient and scalable is a whole new challenge.\"},\n",
    "        {\"text\": \"I find joy in debugging AI models, tweaking parameters, and seeing how they improve.\"},\n",
    "        {\"text\": \"Coding, Netflix, and travel—that's my ideal balance of work, entertainment, and adventure!\"},\n",
    "        {\"text\": \"I am a Level 5 dog bite survivor on the Dunbar scale (1 to 6). It was a tough experience, but it made me stronger.\"},\n",
    "        {\"text\": \"Surviving a Level 5 dog bite taught me resilience. Now, I focus on pushing my limits in tech and life.\"},\n",
    "        {\"text\": \"The Dunbar scale rates dog bite severity, and I experienced one of the highest levels. It’s part of my journey.\"},\n",
    "        {\"text\": \"I believe in overcoming challenges, whether it's debugging AI models or recovering from real-life experiences like a serious dog bite.\"}\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    \n",
    "    df.to_csv('dataset.csv', index=False)\n",
    "    print(f\"Dataset created with {len(df)} examples\")\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  I'm Sajal, a sophomore at MUJ, passionate abou...\n",
      "1  Exploring AI is my favorite thing! From transf...\n",
      "2  Whenever I get free time, I binge-watch Netfli...\n",
      "3  Traveling excites me! I've explored the US, Si...\n",
      "4  There's something about coding AI models that ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('dataset.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\python312\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python312\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\python312\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\python312\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\python312\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\python312\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\python312\\lib\\site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in c:\\python312\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (2.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python312\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python312\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python312\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 24 examples [00:00, 494.58 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"I'm Sajal, a sophomore at MUJ, passionate about LLMs and cutting-edge AI research.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train': 'dataset.csv'})\n",
    "print(dataset[\"train\"][0])  # Check first row to ensure everything looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\python312\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: torch in c:\\python312\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: datasets in c:\\python312\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\python312\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python312\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\python312\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\python312\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.10.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (2.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python312\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python312\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python312\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"I'm Sajal, a sophomore at MUJ, passionate about LLMs and cutting-edge AI research.\"}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset('csv', data_files={'train': 'dataset.csv'})\n",
    "\n",
    "# Print first few rows to check format\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"facebook/opt-1.3b\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=\"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\")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token=\"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\")\n",
    "\n",
    "# Set padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python312\\lib\\site-packages (2.6.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: transformers in c:\\python312\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: datasets in c:\\python312\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\python312\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python312\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\python312\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\python312\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (3.10.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (2.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python312\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python312\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\python312\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'accelerate\"\n"
     ]
    }
   ],
   "source": [
    "!pip install 'accelerate>=0.26.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Using cached accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\python312\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\python312\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\python312\\lib\\site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\python312\\lib\\site-packages (from accelerate) (0.26.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\python312\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python312\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
      "Using cached accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "Installing collected packages: accelerate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python312\\\\Scripts\\\\accelerate.exe' -> 'C:\\\\Python312\\\\Scripts\\\\accelerate.exe.deleteme'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accelerate\n",
      "Version: 1.3.0\n",
      "Summary: Accelerate\n",
      "Home-page: https://github.com/huggingface/accelerate\n",
      "Author: The HuggingFace team\n",
      "Author-email: zach.mueller@huggingface.co\n",
      "License: Apache\n",
      "Location: C:\\Python312\\Lib\\site-packages\n",
      "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\python312\\lib\\site-packages (4.46.2)\n",
      "Collecting transformers[torch]\n",
      "  Using cached transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from transformers[torch]) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\python312\\lib\\site-packages (from transformers[torch]) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python312\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python312\\lib\\site-packages (from transformers[torch]) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers[torch])\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python312\\lib\\site-packages (from transformers[torch]) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python312\\lib\\site-packages (from transformers[torch]) (4.66.4)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\python312\\lib\\site-packages (from transformers[torch]) (2.6.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\python312\\lib\\site-packages (from transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\sajal\\appdata\\roaming\\python\\python312\\site-packages (from accelerate>=0.26.0->transformers[torch]) (6.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch>=2.0->transformers[torch]) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\python312\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->transformers[torch]) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.5)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.3\n",
      "    Uninstalling tokenizers-0.20.3:\n",
      "      Successfully uninstalled tokenizers-0.20.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.46.2\n",
      "    Uninstalling transformers-4.46.2:\n",
      "      Successfully uninstalled transformers-4.46.2\n",
      "  Rolling back uninstall of transformers\n",
      "  Moving to c:\\python312\\lib\\site-packages\\transformers-4.46.2.dist-info\\\n",
      "   from C:\\Python312\\Lib\\site-packages\\~ransformers-4.46.2.dist-info\n",
      "  Moving to c:\\python312\\lib\\site-packages\\transformers\\\n",
      "   from C:\\Python312\\Lib\\site-packages\\~ransformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python312\\\\Scripts\\\\transformers-cli.exe' -> 'C:\\\\Python312\\\\Scripts\\\\transformers-cli.exe.deleteme'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers[torch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\python312\\lib\\site-packages (4.46.2)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\python312\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python312\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\python312\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python312\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Using cached transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.46.2\n",
      "    Uninstalling transformers-4.46.2:\n",
      "      Successfully uninstalled transformers-4.46.2\n",
      "  Rolling back uninstall of transformers\n",
      "  Moving to c:\\python312\\lib\\site-packages\\transformers-4.46.2.dist-info\\\n",
      "   from C:\\Python312\\Lib\\site-packages\\~ransformers-4.46.2.dist-info\n",
      "  Moving to c:\\python312\\lib\\site-packages\\transformers\\\n",
      "   from C:\\Python312\\Lib\\site-packages\\~ransformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python312\\\\Scripts\\\\transformers-cli.exe' -> 'C:\\\\Python312\\\\Scripts\\\\transformers-cli.exe.deleteme'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers==0.20.0\n",
      "  Downloading tokenizers-0.20.0-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\python312\\lib\\site-packages (from tokenizers==0.20.0) (0.26.2)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.0) (2024.7.4)\n",
      "Downloading tokenizers-0.20.0-cp312-none-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.3 MB 325.1 kB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.1/2.3 MB 837.8 kB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.4/2.3 MB 2.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.7/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.8/2.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.1/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.5/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.7/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.9/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.0/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.1/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.2/2.3 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.3 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "Successfully installed tokenizers-0.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers==0.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training setup...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1583: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "def setup_training():\n",
    "    # Load dataset (adjust path if needed)\n",
    "    dataset = load_dataset('csv', data_files={'train': 'dataset.csv'})  # Dataset file in the current directory\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    model_name = \"facebook/opt-1.3b\"  # Model name\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=\"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\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, token=\"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\")\n",
    "    \n",
    "    # Set padding token if not already set\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Tokenize dataset\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],  # Replace \"text\" with the actual column name in your dataset\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "    \n",
    "    tokenized_dataset = dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=dataset[\"train\"].column_names  # Remove original columns to save memory\n",
    "    )\n",
    "    \n",
    "    # Training arguments optimized for CPU\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(\"FINETUNING\", \"results\"),  # Save results in the FINETUNING directory\n",
    "        num_train_epochs=5,  # Number of epochs\n",
    "        per_device_train_batch_size=2,  # Batch size for CPU (keep it small)\n",
    "        save_steps=50,  # Save a checkpoint every 50 steps\n",
    "        save_total_limit=2,  # Keep only the last 2 checkpoints\n",
    "        logging_steps=10,  # Log training progress every 10 steps\n",
    "        learning_rate=2e-5,  # Learning rate\n",
    "        weight_decay=0.01,  # Weight decay for regularization\n",
    "        fp16=False,  # Disable FP16 (not supported on CPU)\n",
    "        gradient_accumulation_steps=4,  # Accumulate gradients over 4 steps\n",
    "        gradient_checkpointing=True,  # Enable gradient checkpointing to save memory\n",
    "        max_grad_norm=0.5,  # Gradient clipping\n",
    "        use_cpu = True  # Ensure no CUDA (GPU) is used\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        data_collator=DataCollatorForLanguageModeling(\n",
    "            tokenizer=tokenizer,\n",
    "            mlm=False  # Causal LM (not masked language model)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return trainer, model, tokenizer\n",
    "\n",
    "def main():\n",
    "    print(\"Starting training setup...\")\n",
    "    trainer, model, tokenizer = setup_training()\n",
    "    \n",
    "    print(\"Beginning training...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    # Change the output directory to FINETUNING\n",
    "    output_dir = os.path.join(\"FINETUNING\", \"my_fine_tuned_model\")  # Save in the FINETUNING directory\n",
    "    print(f\"Saving model to {output_dir}...\")\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    \n",
    "    print(f\"Training complete. Model saved to {output_dir}\")\n",
    "\n",
    "    # Load the fine-tuned model and tokenizer\n",
    "    print(\"Loading fine-tuned model...\")\n",
    "    fine_tuned_model = AutoModelForCausalLM.from_pretrained(output_dir)\n",
    "    fine_tuned_tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "    \n",
    "    # Example: Use the fine-tuned model for text generation\n",
    "    input_text = \"Hello, how are you?\"\n",
    "    inputs = fine_tuned_tokenizer(input_text, return_tensors=\"pt\")\n",
    "    outputs = fine_tuned_model.generate(**inputs, max_length=50)\n",
    "    \n",
    "    generated_text = fine_tuned_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(\"Generated text:\", generated_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
